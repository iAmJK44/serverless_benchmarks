{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# π Estimation with Monte Carlo methods\n",
    "We demonstrate how to run Monte Carlo simulations with lithops over GCP Cloud Functions and AWS Lambda Functions. This notebook contains an example of estimation the number π with Monte Carlo. The goal of this notebook is to demonstrate how loud Functions can benefit Monte Carlo simulations and not how it can be done using lithops.<br>\n",
    "A Monte Carlo algorithm would randomly place points in the square and use the percentage of randomized points inside of the circle to estimate the value of π\n",
    "![pi](https://upload.wikimedia.org/wikipedia/commons/8/84/Pi_30K.gif)\n",
    "\n",
    "Requirements to run this notebook:\n",
    "* AWS Cloud or GCP account. \n",
    "* You will need to have at least one existing object storage bucket. \n",
    "* Lithops 3.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Install dependencies\n",
    "Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from random import random\n",
    "import logging\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    import lithops\n",
    "except:\n",
    "    !{sys.executable} -m pip install lithops\n",
    "    import lithops\n",
    "\n",
    "# you can modify logging level if needed\n",
    "#logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Write Python code that implements Monte Carlo simulation \n",
    "Below is an example of Python code to demonstrate Monte Carlo model for estimate PI\n",
    "\n",
    "'EstimatePI' is a Python class that we use to represent a single PI estimation. You may configure the following parameters:\n",
    "\n",
    "MAP_INSTANCES - number of IBM Cloud Function invocations. Default is 100<br>\n",
    "randomize_per_map - number of points to random in a single invocation. Default is 10,000,000\n",
    "\n",
    "Our code contains two major Python methods:\n",
    "\n",
    "def randomize_points(self,data=None) - a function to random number of points and return the percentage of points\n",
    "    that inside the circle<br>\n",
    "def process_in_circle_points(self, results, futures): - summarize results of all randomize_points\n",
    "  executions (aka \"reduce\" in map-reduce paradigm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP_INSTANCES = 25\n",
    "\n",
    "\n",
    "class EstimatePI:\n",
    "    randomize_per_map = 100000\n",
    "\n",
    "    def __init__(self):\n",
    "        self.total_randomize_points = MAP_INSTANCES * self.randomize_per_map\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"Total Randomize Points: {:,}\".format(self.randomize_per_map * MAP_INSTANCES)\n",
    "\n",
    "    @staticmethod\n",
    "    def predicate():\n",
    "        x = random()\n",
    "        y = random()\n",
    "        return (x ** 2) + (y ** 2) <= 1\n",
    "\n",
    "    def randomize_points(self, data):\n",
    "        in_circle = 0\n",
    "        for _ in range(self.randomize_per_map):\n",
    "            in_circle += self.predicate()\n",
    "        return float(in_circle / self.randomize_per_map)\n",
    "\n",
    "    def process_in_circle_points(self, results):\n",
    "        in_circle_percent = 0\n",
    "        for map_result in results:\n",
    "            in_circle_percent += map_result\n",
    "        estimate_PI = float(4 * (in_circle_percent / MAP_INSTANCES))\n",
    "        return estimate_PI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Configure access to your Cloud Storage and Cloud Functions\n",
    "\n",
    "Configure access details to your AWS or GCP Cloud Functions.  'storage_bucket'  should point to some pre-existing bucket. This bucket will be used by Lithops to store intermediate results. All results will be stored in the folder `lithops.jobs`. For additional configuration parameters see [configuration section](https://github.com/lithops-cloud/lithops)\n",
    "\n",
    "For GCP your `.lithops_config` should be similar to: \n",
    "    \n",
    "    lithops:\n",
    "        storage: gcp_storage\n",
    "        backend: gcp_functions\n",
    "        bucket: lithops-pipelines\n",
    "    \n",
    "    gcp:\n",
    "        credentials_path : <PATH_TO_JSON_KEYS>\n",
    "        region : <GCP_REGION>\n",
    "    \n",
    "    gcp_functions:\n",
    "        region : <GCP_REGION>\n",
    "    \n",
    "    gcp_storage:\n",
    "        region: <GCP_REGION>\n",
    "        storage_bucket: <GCP_STORAGE_BUCKET>\n",
    "\n",
    "For AWS your `.lithops_config` should be similar to: \n",
    "    \n",
    "    lithops:\n",
    "        storage: aws_s3\n",
    "        backend: aws_lambda\n",
    "    \n",
    "    aws:\n",
    "        access_key_id : <AWS_ACCESS_KEY_ID>\n",
    "        secret_access_key : <AWS_SECRET_ACCESS_KEY> \n",
    "        \n",
    "    aws_s3:\n",
    "        storage_bucket: <S3_BUCKET>\n",
    "        region_name : <REGION>\n",
    "    \n",
    "    aws_lambda:\n",
    "        execution_role: <AWS_ROLE_ARN>\n",
    "        region_name: <REGION>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 - Execute simulation with Lithops over AWS Lambda or Google Cloud Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-02 13:04:48,749 [INFO] config.py:134 -- Lithops v2.9.0\n",
      "2023-11-02 13:04:48,827 [INFO] gcp_storage.py:45 -- Google Cloud Storage client created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monte Carlo simulation for estimating PI spawing over 25 IBM Cloud Function invocations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-02 13:04:48,990 [INFO] gcp_functions.py:68 -- Google Cloud Functions client created - Region: us-east1 - Project: pipelines-serverless\n",
      "2023-11-02 13:04:48,993 [INFO] invokers.py:108 -- ExecutorID 821ea9-1 | JobID M000 - Selected Runtime: default-runtime-v39 - 4096MB\n",
      "2023-11-02 13:04:49,984 [INFO] invokers.py:172 -- ExecutorID 821ea9-1 | JobID M000 - Starting function invocation: randomize_points() - Total: 25 activations\n",
      "2023-11-02 13:04:50,005 [INFO] invokers.py:208 -- ExecutorID 821ea9-1 | JobID M000 - View execution logs at /tmp/lithops-jordi/logs/821ea9-1-M000.log\n",
      "2023-11-02 13:04:50,008 [INFO] wait.py:97 -- ExecutorID 821ea9-1 - Waiting for 20% of 25 function activations to complete\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e12655e5800447cafffcf389ba07b02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    0%|          | 0/5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-02 13:04:57,088 [INFO] invokers.py:108 -- ExecutorID 821ea9-1 | JobID R000 - Selected Runtime: default-runtime-v39 - 4096MB\n",
      "2023-11-02 13:04:58,572 [INFO] invokers.py:172 -- ExecutorID 821ea9-1 | JobID R000 - Starting function invocation: process_in_circle_points() - Total: 1 activations\n",
      "2023-11-02 13:04:58,577 [INFO] invokers.py:208 -- ExecutorID 821ea9-1 | JobID R000 - View execution logs at /tmp/lithops-jordi/logs/821ea9-1-R000.log\n",
      "2023-11-02 13:04:58,584 [INFO] wait.py:97 -- ExecutorID 821ea9-1 - Getting results from 26 function activations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9db65b4e7118451eb7180f252169cfc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    0%|          | 0/26  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-02 13:05:06,682 [INFO] executors.py:612 -- ExecutorID 821ea9-1 - Cleaning temporary data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Randomize Points: 2,500,000\n",
      "Estimation of Pi:  3.1420799999999987\n",
      "\n",
      "Completed in: 17.958427906036377 seconds\n"
     ]
    }
   ],
   "source": [
    "iterdata = [0] * MAP_INSTANCES\n",
    "est_pi = EstimatePI()\n",
    "\n",
    "start_time = time()\n",
    "print(\"Monte Carlo simulation for estimating PI spawing over {} IBM Cloud Function invocations\".format(MAP_INSTANCES))\n",
    "# obtain lithops executor\n",
    "pw = lithops.FunctionExecutor(runtime_memory=4096)\n",
    "# execute the code\n",
    "pw.map_reduce(est_pi.randomize_points, iterdata, est_pi.process_in_circle_points)\n",
    "#get results\n",
    "result = pw.get_result()\n",
    "elapsed = time()\n",
    "print(str(est_pi))\n",
    "print(\"Estimation of Pi: \", result)\n",
    "print(\"\\nCompleted in: \" + str(elapsed - start_time) + \" seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
